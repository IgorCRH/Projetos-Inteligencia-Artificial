# -*- coding: utf-8 -*-
"""ClassificacaoAnemia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RVW5nw2qU0W7P0bzJ0_E2ysq7YczU92V

Importando Bibiliotecas e o Dataset
"""

import numpy as np
import pandas as pd
from google.colab import files
from matplotlib import pyplot as plt
import seaborn as sns

uploaded = files.upload()

for filename in uploaded.keys():

    dataset = pd.read_csv(filename)
    print(f"Arquivo {filename} carregado com sucesso!")

"""Informaçõe Estatísticas"""

dataset.describe()

dataset["Diagnosis"].unique()

"""Matriz de Correlação de Diagnóstico"""

fig, ax = plt.subplots(figsize=(12, 8))

fig = sns.heatmap(dataset.drop("Diagnosis",axis=1).corr(), annot=True)

plt.xticks(rotation=30)

plt.yticks(rotation=30)

plt.show()

"""Histograma de Diagnósticos"""

# Crie o histograma com rótulos personalizados
plt.hist(dataset['Diagnosis'], bins=40, edgecolor='black')
plt.xlabel('Diagnóstico')
plt.ylabel('Frequência')
plt.title('Histograma da Coluna Diagnosis')

# Obtenha os rótulos dos diagnósticos
diagnosis_labels = dataset['Diagnosis'].unique()

# Mapeie os rótulos para os índices dos bins
bin_indices = range(len(diagnosis_labels))

# Defina os rótulos no eixo x
plt.xticks(bin_indices, diagnosis_labels, rotation=45)

plt.show()

"""Gráfico em Barra e em Pizza dos Diagnósticos"""

diagnosis_counts = dataset['Diagnosis'].value_counts()

plt.figure(figsize=(10, 6))  # Tamanho da figura
plt.bar(diagnosis_counts.index, diagnosis_counts.values, color='skyblue')  # Criação das barras
plt.xlabel('Diagnóstico')  # Rótulo do eixo x
plt.ylabel('Frequência')  # Rótulo do eixo y
plt.title('Diagnósticos Mais Frequentes')  # Título do gráfico
plt.xticks(rotation=45)  # Rotação dos rótulos no eixo x para melhor visualização
plt.show()

plt.figure(figsize=(10, 8))
plt.pie(diagnosis_counts, labels=diagnosis_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribuição dos Diagnósticos')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""Treinando Modelos e Determinando a Acurácia"""

from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

X = dataset.drop(columns=['Diagnosis'])
y = dataset['Diagnosis']

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modelo Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

# Modelo RandomForest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Modelo XGBoost
xgb_model = XGBClassifier(random_state=42)
xgb_model.fit(X_train, y_train)

dt_pred = dt_model.predict(X_test)
rf_pred = rf_model.predict(X_test)
xgb_pred = xgb_model.predict(X_test)

dt_accuracy = accuracy_score(y_test, dt_pred)
rf_accuracy = accuracy_score(y_test, rf_pred)
xgb_accuracy = accuracy_score(y_test, xgb_pred)

print("Precisão da Decision Tree:", dt_accuracy)
print("Precisão do RandomForest:", rf_accuracy)
print("Precisão do XGBoost:", xgb_accuracy)

if dt_accuracy == rf_accuracy == xgb_accuracy:
    print("Todos os modelos tiveram a mesma precisão.")
else:
    best_model = max(dt_accuracy, rf_accuracy, xgb_accuracy)
    if best_model == dt_accuracy:
        print("Decision Tree teve melhor desempenho.")
    elif best_model == rf_accuracy:
        print("RandomForest teve melhor desempenho.")
    else:
        print("XGBoost teve melhor desempenho.")

from sklearn.metrics import classification_report
print("Relatório de Classificação para Decision Tree:")
print(classification_report(y_test, dt_pred))

print("Relatório de Classificação para RandomForest:")
print(classification_report(y_test, rf_pred))

print("Relatório de Classificação para XGBoost:")
print(classification_report(y_test, xgb_pred))

from sklearn.metrics import confusion_matrix

dt_cm = confusion_matrix(y_test, dt_pred)

rf_cm = confusion_matrix(y_test, rf_pred)

xgb_cm = confusion_matrix(y_test, xgb_pred)

plt.figure(figsize=(18, 5))

plt.subplot(1, 3, 1)
sns.heatmap(dt_cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title('Matriz de Confusão - Decision Tree')
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')

plt.subplot(1, 3, 2)
sns.heatmap(rf_cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title('Matriz de Confusão - Random Forest')
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')

plt.subplot(1, 3, 3)
sns.heatmap(xgb_cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title('Matriz de Confusão - XGBoost')
plt.xlabel('Predito')
plt.ylabel('Verdadeiro')

plt.tight_layout()
plt.show()

